Download docker desktop

docker desktop is just a GUI and docker daemon is the actual thing.

commands:

docker -v 

docker =>>>> to view all docker commands

docker run -it ubuntu =>>>> -it is for interactive mode and ubuntu is the name of image -> this command will create a container with the ubuntu image and if it is not present locally then it will download the image from the docker hub

Docker hub is like github of containers where we can find all public containers

Each container is completely isolated from the host environment everything you do there stays there

Every container has a unique ID and a random name by default
to give custom name-> docker run -it --name my_container <image-name>

Ctrl + D or exit will exit the container terminal and stop the container

docker container ls =>>>> it will list all the running containers
docker container ls -a =>>> will list all containers

docker start <container-name> =>>>> will run the stopped container
docker stop <container-name> =>>>> will stop the running container

docker exec <container-name> ls => it will run the ls command in that container, give the result and exit the container terminal

To keep the container terminal running we can use:
docker exec -it <container-name> bash

docker images OR docker image ls =>>>> it will list all the locally present images

PORT MAPPING:
docker run -it -p <my-machine-port>:<container-port> <image-name> =>>>> this will map the port of the container to the machine or we can say it will expose the port of the container
docker run -it -p 1025:1025 mailhog/mailhog

To pass environment variable to the container
docker run -it -e key=value -e key2=value <image-name>


Containerization of Nodejs server with docker
1.create a file "Dockerfile" with this exact name and no extension in the root folder of project
2.Syntax of Dockerfile
```
FROM ubuntu

RUN apt-get update
RUN apt-get install -y curl
RUN curl -sL https://deb.nodesource.com/setup_18.x | bash -
RUN apt-get upgrade -y
RUN apt-get install -y Nodejs

COPY package.json package.json
COPY package-lock.json package-lock.json
COPY main.js main.js

RUN npm install

ENTRYPOINT [ "node", "main.js" ]
```
2. Instead of installing node on ubuntu we can directly do 
```
FROM node

COPY package.json package.json
COPY package-lock.json package-lock.json
COPY main.js main.js

RUN npm install

ENTRYPOINT [ "node", "main.js" ]
```
3. docker build . -t <image-name> =>>>> -t is for tag (to give your image a name) ->>> this will locally create an image of the project

LAYER Caching:
suppose if we put the copy lines before installing node on ubuntu then if the main.js file is changed it will rerun all the lines below. so to optimize the build time , we should add common lines first so that they can be cached during repeated builds

To publish image to dockerHub:
1. sign in to docker hub
2. Create repository
3. make sure you are logged in on the terminal before pushing
docker login ->>> to login on the terminal
4. docker push <image-name> =>>>> image name should be same as it is showing in the repository

In real world, one project needs more than one container as they can be using redis, postgres etc. so instead of creating all the containers manually we can use docker hub
1.Create a docker-compose.yml in root folder
# we can comment using # in .yml file
2.Syntax
```
version: '3.8' # version of docker compose

services:
  postgres:
    image: postgres # will be pulled from hub.docker.com
    ports:
      - '5432:5432'
    environment:
     POSTGRES_USER: postgres
     POSTGRES_DB: review
     POSTGRES_PASSWORD: password

  redis:
    image: redis
    ports:
     - '6379:6379'
```
3. docker compose up =>> this will run all the services defined in yml file and if this does not work. then use sudo
4. docker compose down =>> will stop the running services
5. docker compose up -d =>> this will run in background(detached mode)

--------------------------Advanced Docker:-------------------------------

Docker networking:
docker network inspect bridge =>> will give the information of the connected containers which are using bridge network(bridge is assigned by default)

docker network ls =>> list all the available network

docker run -it --network=host <image-name> =>>>explicitly specify the network type   =>> while using host network, we do not need to use port mapping as the container is using the host network

if we set --network=none, then we can disable the network in container

Custom network:
docker network create -d bridge <custom-name-of-network>

now we can use
docker run -it --network=<custom-name-of-network> <image-name>

if we create two container with same network then those containers can communicate with each other just by the container name
PING <container-name> =>> it will resolve the ip by itself

to see the ip address of the containers 
docker network inspect <custom-name-of-network>
